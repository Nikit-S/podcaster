import os
import sys
import torch
from huggingface_hub import login
from pyannote.audio import Pipeline, Model
from faster_whisper import WhisperModel
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    stream=sys.stdout
)
logger = logging.getLogger(__name__)

def download_diarization_model(hf_token):
    """Download and cache the diarization model"""
    logger.info("üì• Downloading pyannote/speaker-diarization-3.1 model...")
    try:
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            use_auth_token=hf_token
        )
        logger.info("‚úÖ Diarization model downloaded successfully")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error downloading diarization model: {str(e)}")
        return False

def download_segmentation_model(hf_token):
    """Download and cache the segmentation model correctly"""
    logger.info("üì• Downloading pyannote/segmentation-3.0 model...")
    try:
        # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ segmentation –º–æ–¥–µ–ª–∏
        model = Model.from_pretrained(
            "pyannote/segmentation-3.0",
            use_auth_token=hf_token
        )
        logger.info("‚úÖ Segmentation model downloaded successfully")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error downloading segmentation model: {str(e)}")
        return False

def download_whisper_model(model_size="medium"):
    """Download and cache the Whisper model"""
    logger.info(f"üì• Downloading Whisper {model_size} model...")
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        compute_type = "float16" if device == "cuda" else "float32"
        
        model = WhisperModel(model_size, device=device, compute_type=compute_type)
        logger.info(f"‚úÖ Whisper {model_size} model downloaded successfully (device: {device})")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error downloading Whisper model: {str(e)}")
        return False

if __name__ == "__main__":
    hf_token = os.environ.get("HF_TOKEN")
    
    if not hf_token:
        logger.error("‚ùå HF_TOKEN environment variable is not set!")
        sys.exit(1)
    
    # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
    try:
        login(token=hf_token, add_to_git_credential=False)
        logger.info("‚úÖ Successfully logged in to Hugging Face Hub")
    except Exception as e:
        logger.error(f"‚ùå Failed to login to Hugging Face Hub: {str(e)}")
        sys.exit(1)
    
    success = True
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏
    if not download_diarization_model(hf_token):
        success = False
    
    # –°–∫–∞—á–∏–≤–∞–µ–º segmentation –º–æ–¥–µ–ª—å –ü–†–ê–í–ò–õ–¨–ù–´–ú —Å–ø–æ—Å–æ–±–æ–º
    if not download_segmentation_model(hf_token):
        success = False
    
    # –°–∫–∞—á–∏–≤–∞–µ–º Whisper –º–æ–¥–µ–ª—å
    model_size = os.environ.get("WHISPER_MODEL_SIZE", "medium")
    if not download_whisper_model(model_size):
        success = False
    
    if success:
        logger.info("\nüéâ All models downloaded successfully!")
        sys.exit(0)
    else:
        logger.error("\n‚ùå Some models failed to download. Build will fail.")
        sys.exit(1)